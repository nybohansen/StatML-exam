\relax 
\catcode`"\active
\catcode 95\active
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\newlabel{sec:question_1}{{}{1}{Question 1\relax }{section*.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Histogram of normalized frequencies of the classes found in the dataset.\relax }}{1}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig1}{{1}{1}{Histogram of normalized frequencies of the classes found in the dataset.\relax \relax }{figure.caption.2}{}}
\newlabel{sec:question_2}{{}{2}{Question 2\relax }{section*.3}{}}
\newlabel{fig0}{{2(a)}{2}{Subfigure 2(a)\relax }{subfigure.2.1}{}}
\newlabel{sub@fig0}{{(a)}{2}{Subfigure 2(a)\relax }{subfigure.2.1}{}}
\newlabel{fig2}{{2(b)}{2}{Subfigure 2(b)\relax }{subfigure.2.2}{}}
\newlabel{sub@fig2}{{(b)}{2}{Subfigure 2(b)\relax }{subfigure.2.2}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Eigenvalues of the sorted components}}}{2}{subfigure.2.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$90 \%$ of the variance is contained within the first $305$ principal components.}}}{2}{subfigure.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The dataset projected on to the first two PCA components. Each color/shape represent a different class. There are in total five classes.\relax }}{3}{figure.caption.5}}
\newlabel{fig3}{{2}{3}{The dataset projected on to the first two PCA components. Each color/shape represent a different class. There are in total five classes.\relax \relax }{figure.caption.5}{}}
\newlabel{sec:question_3}{{}{3}{Question 3\relax }{section*.6}{}}
\citation{hunch}
\newlabel{fig4}{{3(a)}{4}{Subfigure 3(a)\relax }{subfigure.3.1}{}}
\newlabel{sub@fig4}{{(a)}{4}{Subfigure 3(a)\relax }{subfigure.3.1}{}}
\newlabel{fig5}{{3(b)}{4}{Subfigure 3(b)\relax }{subfigure.3.2}{}}
\newlabel{sub@fig5}{{(b)}{4}{Subfigure 3(b)\relax }{subfigure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of the sensitivity in the initialization process. Both figures where made by choosing the cluster centroids randomly from the dataset, but finds completely different centroids.\relax }}{4}{figure.caption.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Random initialization of cluster centroids. Two centroids inside `red/cyan' class, none in `blue' class.}}}{4}{figure.caption.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Random initialization of cluster centroids. One centroid inside `red/cyan' and one in `blue' class.}}}{4}{figure.caption.7}}
\newlabel{label}{{3}{4}{Illustration of the sensitivity in the initialization process. Both figures where made by choosing the cluster centroids randomly from the dataset, but finds completely different centroids.\relax \relax }{figure.caption.7}{}}
\newlabel{sec:question_4}{{}{4}{Question 4\relax }{section*.8}{}}
\citation{LDAslides}
\citation{assignment2}
\citation{assignment3}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces This table shows the average accuracy over a 5-fold cross validation when running LDA on the entire test dataset.\relax }}{5}{table.caption.13}}
\newlabel{table10}{{1}{5}{This table shows the average accuracy over a 5-fold cross validation when running LDA on the entire test dataset.\relax \relax }{table.caption.13}{}}
\newlabel{sec:question_5}{{}{5}{Question 5\relax }{section*.9}{}}
\newlabel{sub:cross_validation}{{}{5}{Cross-validation\relax }{section*.10}{}}
\newlabel{sub:computation_of_test_errors}{{}{5}{Computation of test errors\relax }{section*.11}{}}
\newlabel{sub:linear_classification}{{}{5}{Linear classification\relax }{section*.12}{}}
\citation{assignment3}
\citation{libsvm}
\citation{Wu07doi10.1007/s10115-007-0114-2}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Accuracy given different SVM model parameters. The model is most accurate when $i=1$ and $C=10$, yielding a accuracy of $\approx 93\%$\relax }}{6}{table.caption.15}}
\newlabel{table4}{{2}{6}{Accuracy given different SVM model parameters. The model is most accurate when $i=1$ and $C=10$, yielding a accuracy of $\approx 93\%$\relax \relax }{table.caption.15}{}}
\newlabel{sub:non_linear_classification}{{}{6}{Non-linear classification\relax }{section*.14}{}}
\newlabel{eq21}{{5}{6}{Non-linear classification\relax }{equation.0.5}{}}
\newlabel{sec:question_6}{{}{6}{Question 6\relax }{section*.16}{}}
\newlabel{sub:linear_classification2}{{}{6}{Linear classification\relax }{section*.17}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces This table shows the average accuracy over a 5-fold cross validation when running LDA on the entire test dataset.\relax }}{7}{table.caption.18}}
\newlabel{table3}{{3}{7}{This table shows the average accuracy over a 5-fold cross validation when running LDA on the entire test dataset.\relax \relax }{table.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces This table shows the average accuracy over a 5-fold cross validation when running kNN on the entire test dataset. As can be seen $k=20$ yields the best accuracy.\relax }}{7}{table.caption.20}}
\newlabel{table2}{{4}{7}{This table shows the average accuracy over a 5-fold cross validation when running kNN on the entire test dataset. As can be seen $k=20$ yields the best accuracy.\relax \relax }{table.caption.20}{}}
\newlabel{sub:non_linear_classification2}{{}{7}{Non-linear classification\relax }{section*.19}{}}
\newlabel{sec:question_7}{{}{7}{Question 7\relax }{section*.21}{}}
\citation{resultsURL}
\citation{Bishop:2006:PRM:1162264}
\newlabel{sub:binary_classification}{{}{8}{Testing binary classification using LDA\relax }{section*.22}{}}
\newlabel{ssub:testing_binary_classification_using_svm}{{}{8}{Testing binary classification using SVM\relax }{section*.23}{}}
\newlabel{sub:multi_class_classification}{{}{8}{Testing multi-class classification with LDA\relax }{section*.24}{}}
\newlabel{sub:testing_multi_class_classification_using_knn}{{}{8}{Testing multi-class classification using kNN\relax }{section*.25}{}}
\newlabel{sub:overall_performance}{{}{8}{Overall performance\relax }{section*.26}{}}
\newlabel{sec:question_8}{{}{8}{Question 8\relax }{section*.27}{}}
\citation{DBLP:journals/corr/abs-0804-4809}
\citation{assignment}
\citation{assignment}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Performance of using linear regression when doing binary and multi-class classification. In average the classifier is correct in $\approx 88\%$ of the cases when doing binary classification, and $\approx 11\%$ when doing multi-class classification.\relax }}{9}{table.caption.28}}
\newlabel{table1}{{5}{9}{Performance of using linear regression when doing binary and multi-class classification. In average the classifier is correct in $\approx 88\%$ of the cases when doing binary classification, and $\approx 11\%$ when doing multi-class classification.\relax \relax }{table.caption.28}{}}
\newlabel{sec:question_9}{{}{9}{Question 9\relax }{section*.29}{}}
\newlabel{bayes}{{9}{9}{Question 9\relax }{equation.0.9}{}}
\bibstyle{abbrv}
\bibdata{bibliography}
\bibcite{Bishop:2006:PRM:1162264}{1}
\bibcite{DBLP:journals/corr/abs-0804-4809}{2}
\bibcite{resultsURL}{3}
\bibcite{hunch}{4}
\bibcite{libsvm}{5}
\bibcite{LDAslides}{6}
\bibcite{assignment2}{7}
\bibcite{assignment3}{8}
\bibcite{assignment}{9}
\bibcite{Wu07doi10.1007/s10115-007-0114-2}{10}
\newlabel{LastPage}{{}{10}{}{page.10}{}}
